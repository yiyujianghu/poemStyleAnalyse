# apollo-cnn-rnn for text classification<br>

-------------------------------------------------------

version = 0.0.1<br>
text classification by char<br>
数据文件在./data/goodbad下边，包括训练数据、测试数据以及词汇表<br>
数据格式为“标签\t文本”<br>

-------------------------------------------------------
-----5k条数据、char分类、learning_rate = 1e-3-----<br>
利好/利空/中性 三分类结果<br>
Test Loss:&#160;1.3, &#160;&#160;&#160;&#160;&#160;Test Acc:&#160;70.25%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.63      0.63      0.63      1000
         利好       0.66      0.61      0.63       998
         利空       0.81      0.87      0.84      1000

avg&#160;&#160;/total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.70&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.70&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.70&#160;&#160;&#160;&#160;&#160;&#160;&#160;
2998<br>

Confusion Matrix...<br>
&#160;&#160;[[627 270 103]<br>
&#160;&#160;&#160;[289 608 101]<br>
&#160;&#160;&#160;[ 80  49 871]]<br>
Time usage: 0:00:03<br>


-------------------------------------------------------

以下都是针对5w条训练数据所得到的对比结果

-------------------------------------------------------

利好/利空/中性 三分类结果<br>
Test Loss:&#160;0.62, &#160;&#160;&#160;&#160;&#160;Test Acc:&#160;72.11%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.63      0.64      0.63      9996
         利好       0.74      0.74      0.74     10000
         利空       0.80      0.79      0.79      9998

avg&#160;&#160;/ total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
&#160;&#160;[[6393 2062 1541]<br>
&#160;&#160;&#160;[2137 7384  479]<br>
&#160;&#160;&#160;[1663  484 7851]]<br>
 <br>

利好/利空 二分类结果<br>
Test Loss:   0.21, Test Acc:  91.59%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         利好       0.92      0.91      0.92      9999
         利空       0.91      0.92      0.92     10000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
19999<br>

Confusion Matrix...<br>
[[9146  853]<br>
 [ 829 9171]]<br>

-------------------------------------------------------

version = 0.0.2<br>
text classification by word<br>
利用jieba分词<br>
更新utils下的一些小工具，更新数据文件夹中经过分词后的词汇表<br>
（分类效果与单字分类效果差不多）<br>
利好/利空/中性 三分类结果<br>
Test Loss:   0.63, Test Acc:  72.14%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support
             
         中性       0.65      0.59      0.62      9996
         利好       0.76      0.71      0.74     10000
         利空       0.74      0.87      0.80      9998

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.72&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
[[5897 1829 2270]<br>
 [2140 7076  784]<br>
 [ 987  345 8666]]<br>
 <br>

利好/利空 二分类结果<br>
Test Loss:   0.22, Test Acc:  91.54%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         利好       0.91      0.92      0.92      9999
         利空       0.92      0.91      0.92     10000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.92&#160;&#160;&#160;&#160;&#160;&#160;&#160;
19999<br>

Confusion Matrix...<br>
[[9173  826]<br>
 [ 865 9135]]<br>
 <br>
 
-------------------------------------------------------
 
version = 0.0.3<br>
利用jieba分词，利用gensim的CBOW词向量模型<br>
更新utils中的词向量表和词汇表<br>
（分类效果并不理想）<br>
利好/利空/中性 三分类结果<br>
Test Loss:   0.71, Test Acc:  68.41%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.58      0.60      0.59      9996
         利好       0.74      0.66      0.70     10000
         利空       0.74      0.79      0.77      9998

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.69&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.68&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.68&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
[[5988 1953 2055]<br>
 [2714 6612  674]<br>
 [1677  403 7918]]<br>
 <br>

利好/利空 二分类结果<br>
Test Loss:   0.27, Test Acc:  89.18%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         利好       0.90      0.88      0.89      9999
         利空       0.88      0.90      0.89     10000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.89&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.89&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.89&#160;&#160;&#160;&#160;&#160;&#160;&#160;
19999<br>

Confusion Matrix...<br>
[[8807 1192]<br>
 [ 972 9028]]<br>
<br>

-------------------------------------------------------

version = 0.0.4<br>
通过改变分词方式、增加词库数据、增加词向量min_count数值、增加训练样本数、降低学习率等各种方法比较，发现：<br>
1、优化词库、使分词更加准确会带来效果提升，但还需要很多工作。目前只是将搜狗的金融词库加入分词词库中，取得了较好的分词效果；<br>
2、增加min_count可过滤掉无关词汇，可使得准确率有微小的提高；<br>
3、增加样本数量当然会使准确率提升，但除了某一个6w数据的样本准确率上升到80%以外，其余未有较大提升，可知随机抽象的样本也具有偏差性；<br>
4、降低学习率可使得后段loss下降更加平稳，增加后期准确率；<br>
5、可以尝试几种方法的融合，观察是否可以获得叠加效果；<br>

-----5w条数据、word分类、增加分词词库、min_count=800-----<br>
Test Loss:   0.65, Test Acc:  72.82%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.63      0.66      0.65      9996
         利好       0.76      0.73      0.75     10000
         利空       0.79      0.79      0.79      9998

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
[[6579 1870 1547]<br>
 [2147 7323  530]<br>
 [1660  399 7939]]<br>
 <br>
 
-----5w条数据、word分类、增加分词词库、增加停用词、min_count=1000-----<br>
Test Loss:   0.64, Test Acc:  72.95%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.67      0.57      0.62      9996
         利好       0.73      0.78      0.76     10000
         利空       0.77      0.83      0.80      9998

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.73&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
[[5744 2354 1898]<br>
 [1619 7836  545]<br>
 [1180  518 8300]]<br>
<br>

-----5w条数据、char分类、learning_rate = 1e-4-----<br>
Test Loss:    0.6, Test Acc:  74.08%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.67      0.62      0.65      9996
         利好       0.75      0.77      0.76     10000
         利空       0.79      0.83      0.81      9998

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29994<br>

Confusion Matrix...<br>
[[6246 2135 1615]<br>
 [1755 7718  527]<br>
 [1277  466 8255]]<br>
 <br>

-----7w条数据、char分类、learning_rate = 1e-4-----<br>
Test Loss:   0.59, Test Acc:  75.06%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.68      0.66      0.67      9999
         利好       0.78      0.74      0.76      9999
         利空       0.79      0.85      0.82     10000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29998<br>

Confusion Matrix...<br>
[[6633 1702 1664]<br>
 [2010 7376  613]<br>
 [1152  342 8506]]<br>
 <br>

-----8w5条数据、char分类、learning_rate = 1e-4-----<br>
Test Loss:   0.57, Test Acc:  75.23%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.70      0.63      0.66      9998
         利好       0.76      0.78      0.77      9996
         利空       0.79      0.86      0.82      9999

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29993<br>

Confusion Matrix...<br>
[[6258 1994 1746]<br>
 [1690 7755  551]<br>
 [1026  422 8551]]<br>
 <br>

-----6w条数据、char分类、learning_rate = 1e-4-----<br>
（较好的一个随机数据集，训练准确率一度达到88%，说明val与train匹配度较高，也说明最终结果相当依赖于数据集质量）<br>
Test Loss:   0.78, Test Acc:  73.63%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.65      0.67      0.66     15000
         利好       0.75      0.74      0.75     15000
         利空       0.80      0.80      0.80     14999

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.74&#160;&#160;&#160;&#160;&#160;&#160;&#160;
44999<br>

Confusion Matrix...<br>
[[10066  2814  2120]<br>
 [ 3143 11056   801]<br>
 [ 2214   776 12009]]<br>
 <br>

-----15w+11w+10w非平衡数据、char分类、learning_rate = 1e-4-----<br>
（非平衡数据集准确率会略有下降，但是可看出分类效果更倾向于多数数据，中性数据样本的分类准确率明显上升）<br>
Test Loss:   0.57, Test Acc:  74.93%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.73      0.73      0.73     15097
         利好       0.75      0.72      0.74     10897
         利空       0.78      0.80      0.79      9896

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
35890<br>

Confusion Matrix...<br>
[[11038  2292  1767]<br>
 [ 2534  7900   463]<br>
 [ 1579   361  7956]]<br>
 <br>

-----9w+11w+10w非平衡数据、char分类、learning_rate = 1e-4-----<br>

Test Loss:   0.57, Test Acc:  75.66%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.66      0.62      0.64      8993
         利好       0.79      0.78      0.78     10902
         利空       0.80      0.85      0.82      9898

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.76&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
29793<br>

Confusion Matrix...<br>
[[5611 1870 1512]<br>
 [1796 8536  570]<br>
 [1043  460 8395]]<br>
<br>

-----6w+8w+7w非平衡数据、char分类、learning_rate = 1e-4-----<br>
（构造了一个非平衡数据集，其中压制中性样本的比例，提高利好样本的比例，这样得到的结果利好与利空的分类准确率与召回率都在80%左右）<br>
Test Loss:   0.57, Test Acc:  75.13%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.65      0.57      0.60      5999
         利好       0.78      0.81      0.79      7999
         利空       0.79      0.85      0.82      6999

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.75&#160;&#160;&#160;&#160;&#160;&#160;&#160;
20997<br>

Confusion Matrix...<br>
[[3391 1461 1147]<br>
 [1151 6440  408]<br>
 [ 698  358 5943]]<br>
<br>
<br>

### 更新于2018-11-14
#### content数据结果
* 数据清洗，content数据
4w之前的数据，较为准确<br>
Test Loss:   0.41, Test Acc:  84.07%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.81      0.80      0.80      5000
         利好       0.87      0.90      0.88      5000
         利空       0.84      0.82      0.83      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[4003  388  609]<br>
 [ 341 4484  175]<br>
 [ 612  265 4123]]<br>

* 数据增强
Test Loss:   0.43, Test Acc:  83.79%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.81      0.79      0.80      5000
         利好       0.88      0.89      0.88      5000
         利空       0.83      0.83      0.83      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[3965  378  657]<br>
 [ 362 4434  204]<br>
 [ 576  254 4170]]<br>



* 数据迁移
采用content训练的模型在title数据上做分类预测<br>
Test Loss:    0.9, Test Acc:  66.57%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.64      0.42      0.51      5000
         利好       0.59      0.81      0.68      5000
         利空       0.79      0.76      0.78      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.67&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.67&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.66&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[2124 2113  763]<br>
 [ 712 4053  235]<br>
 [ 503  689 3808]]<br>


* 数据过滤-1
采用数据过滤的方法去除模棱两可的数据，提高数据集的质量。train与val都做过滤<br>
Test Loss:    0.5, Test Acc:  83.71%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.82      0.78      0.80      5000
         利好       0.87      0.89      0.88      5000
         利空       0.82      0.84      0.83      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[3894  408  698]<br>
 [ 330 4461  209]<br>
 [ 532  266 4202]]<br>

* 数据过滤-2
采用数据过滤的方法去除模棱两可的数据，提高数据集的质量。只对train做过滤<br>
Test Loss:   0.63, Test Acc:  84.13%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.81      0.80      0.81      5000
         利好       0.88      0.88      0.88      5000
         利空       0.83      0.84      0.84      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[3989  375  636]<br>
 [ 356 4424  220]<br>
 [ 557  237 4206]]<br>

* 增加数据集规模
数据集规模增加到5.5w，其中train占85%，test占10%，val占5%<br>
Test Loss:   0.42, Test Acc:  83.28%
Precision, Recall and F1-Score...
             precision    recall  f1-score   support

         中性       0.80      0.79      0.79      5500
         利好       0.89      0.87      0.88      5500
         利空       0.81      0.83      0.82      5500

avg / total       0.83      0.83      0.83     16500

Confusion Matrix...
[[4351  327  822]
 [ 457 4800  243]
 [ 648  262 4590]]

* 非平衡数据集
抑制中性样本的数量，提高利好和利空的准确率和召回率<br>
Test Loss:    0.4, Test Acc:  84.28%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.80      0.77      0.78      4500
         利好       0.87      0.91      0.89      5500
         利空       0.85      0.83      0.84      5500

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.84&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15500<br>

Confusion Matrix...<br>
[[3459  422  619]<br>
 [ 287 5028  185]<br>
 [ 601  323 4576]]<br>
 <br>
`tips `通过混淆矩阵可以看出，结果中的利好样本一共有5773个，其中利空被分到利好的有323个，占比5.59%；结果中利空样本一共有5380个，其中利好被分到利空的有185个，占比3.43%；<br>

* 现有数据的二分类
Test Loss:   0.18, Test Acc:  93.44%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.93      0.94      0.93      5500
         利好       0.94      0.93      0.93      5500

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.93&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.93&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.93&#160;&#160;&#160;&#160;&#160;&#160;&#160;
11000<br>

Confusion Matrix...<br>
[[5177  323]<br>
 [ 399 5101]]<br>

#### title数据结果
* 数据清洗，title数据
Test Loss:   0.49, Test Acc:  80.47%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.73      0.74      0.73      5000
         利好       0.83      0.82      0.82      5000
         利空       0.86      0.86      0.86      5000

avg / total&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.81&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.80&#160;&#160;&#160;&#160;&#160;&#160;&#160;
0.81&#160;&#160;&#160;&#160;&#160;&#160;&#160;
15000<br>

Confusion Matrix...<br>
[[3706  721  573]<br>
 [ 797 4078  125]<br>
 [ 593  120 4287]]<br>

* 非平衡数据集
抑制中性样本的数量，提高利好和利空的准确率和召回率<br>
Test Loss:   0.48, Test Acc:  80.72%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.71      0.68      0.69      4500
         利好       0.84      0.83      0.84      5500
         利空       0.85      0.88      0.86      5500

avg / total       0.81      0.81      0.81     15500<br>

Confusion Matrix...<br>
[[3060  723  717]<br>
 [ 739 4592  169]<br>
 [ 511  129 4860]]<br>


* 增加数据集规模
数据集规模增加到5.5w，其中train占85%，test占10%，val占5%<br>
Test Loss:   0.47, Test Acc:  81.26%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.71      0.71      0.71      4500
         利好       0.84      0.84      0.84      5500
         利空       0.87      0.88      0.87      5500

avg / total       0.81      0.81      0.81     15500<br>

Confusion Matrix...<br>
[[3175  716  609]<br>
 [ 764 4595  141]<br>
 [ 531  143 4826]]<br>

* 现有数据的二分类<br>
Test Loss:   0.16, Test Acc:  94.79%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         利好       0.95      0.94      0.95      5500
         利空       0.94      0.95      0.95      5500

avg / total       0.95      0.95      0.95     11000<br>

Confusion Matrix...<br>
[[5195  305]<br>
 [ 268 5232]]<br>

* 缩小模型容量-300
修改超参数，将句子长度由1500缩小到300,假设每句话为15个字，则总共读20次<br>
Test Loss:    0.5, Test Acc:  81.01%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.69      0.73      0.71      4500
         利好       0.85      0.82      0.84      5500
         利空       0.88      0.86      0.87      5500

avg / total       0.81      0.81      0.81     15500<br>

Confusion Matrix...<br>
[[3284  670  546]<br>
 [ 835 4535  130]<br>
 [ 614  149 4737]]<br>

* 缩小模型容量-150
修改超参数，将句子长度由300缩小到150,假设每句话为15个字，则总共读10次<br>
Test Loss:   0.47, Test Acc:  81.26%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.71      0.71      0.71      4500
         利好       0.85      0.83      0.84      5500
         利空       0.86      0.89      0.87      5500

avg / total       0.81      0.81      0.81     15500<br>

Confusion Matrix...<br>
[[3180  686  634]<br>
 [ 803 4540  157]<br>
 [ 493  131 4876]]<br>


* 缩小模型容量-50
修改超参数，将句子长度由150缩小到50,假设每个标题为15个字，则总共读3次，最长的标题是37个字，相当于读1.3次<br>
Test Loss:   0.47, Test Acc:  81.23%<br>
Precision, Recall and F1-Score...<br>
             precision    recall  f1-score   support

         中性       0.70      0.72      0.71      4500
         利好       0.86      0.81      0.83      5500
         利空       0.86      0.89      0.87      5500

avg / total       0.81      0.81      0.81     15500<br>

Confusion Matrix...<br>
[[3249  625  626]<br>
 [ 875 4467  158]<br>
 [ 509  117 4874]]<br>



`conclusion`<br>
感觉对比后准确率变化不大，但模型变小后速度有明显提升，因此实际工程中采用参数更少的小型模型；


-----
`tips` 关于predict中几种增强方式的测试（仅供参考）：<br>
1、for循环填充：<br>
正确率为 94.4%, 84.1%, 83.6%<br>
2、1500//len(content)：<br>
正确率为 84.2%, 77.3%, 76.9%<br>
3、1 + 1500//len(content)：<br>
正确率为 94.4%, 84.1%, 83.6%<br>
4、content+"。"：<br>
正确率为 94.2%, 84.0%, 83.5%<br>

